{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#word2vec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is equivalent to `demo-word.sh`, `demo-analogy.sh`, `demo-phrases.sh` and `demo-classes.sh` from Google."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download some data, for example: [http://mattmahoney.net/dc/text8.zip](http://mattmahoney.net/dc/text8.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `word2phrase` to group up similar words \"Los Angeles\" to \"Los_Angeles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file /Users/gautamchheda/Downloads/text8\n",
      "Words processed: 17000K     Vocab size: 4399K  \n",
      "Vocab size (unigrams + bigrams): 2419827\n",
      "Words in train file: 17005206\n",
      "Words written: 17000K\r"
     ]
    }
   ],
   "source": [
    "word2vec.word2phrase('/Users/gautamchheda/Downloads/text8', '/Users/gautamchheda/Downloads/text8-phrases', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a `text8-phrases` that we can use as a better input for `word2vec`.\n",
    "Note that you could easily skip this previous step and use the origial data as input for `word2vec`.\n",
    "\n",
    "Train the model using the `word2phrase` output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file /Users/gautamchheda/Downloads/text8-phrases\n",
      "Vocab size: 98331\n",
      "Words in train file: 15857306\n",
      "Alpha: 0.000002  Progress: 100.04%  Words/thread/sec: 365.38k  "
     ]
    }
   ],
   "source": [
    "word2vec.word2vec('/Users/gautamchheda/Downloads/text8-phrases', '/Users/gautamchheda/Downloads/text8.bin', size=100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That generated a `text8.bin` file containing the word vectors in a binary format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the clustering of the vectors based on the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training using file /Users/gautamchheda/Downloads/text8\n",
      "Vocab size: 71291\n",
      "Words in train file: 16718843\n",
      "Alpha: 0.000002  Progress: 100.03%  Words/thread/sec: 364.16k  "
     ]
    }
   ],
   "source": [
    "word2vec.word2clusters('/Users/gautamchheda/Downloads/text8', '/Users/gautamchheda/Downloads/text8-clusters.txt', 100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That created a `text8-clusters.txt` with the cluster for every word in the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `word2vec` binary file created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.load('/Users/gautamchheda/Downloads/text8.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the vocabulaty as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'</s>', u'the', u'of', ..., u'dakotas', u'nias', u'burlesques'],\n",
       "      dtype='<U78')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or take a look at the whole matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98331, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14333282,  0.15825513, -0.13715845, ...,  0.05456942,\n",
       "         0.10955409,  0.00693387],\n",
       "       [ 0.05901973, -0.03838892,  0.10086869, ..., -0.10895406,\n",
       "        -0.04325397,  0.00908804],\n",
       "       [ 0.17550297, -0.02656363, -0.04145248, ..., -0.02540955,\n",
       "         0.13294062,  0.11193433],\n",
       "       ...,\n",
       "       [-0.03154316,  0.07935622,  0.06886648, ...,  0.12321164,\n",
       "        -0.01726373, -0.0321489 ],\n",
       "       [ 0.08473612, -0.01125982,  0.15778488, ...,  0.09312072,\n",
       "        -0.21965933, -0.08323528],\n",
       "       [ 0.0689628 , -0.03754506,  0.0347125 , ...,  0.0051401 ,\n",
       "        -0.10758115, -0.07847002]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retreive the vector of individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['dog'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09261248, -0.03804511,  0.15976225,  0.01918418,  0.06726611,\n",
       "       -0.07513122,  0.15003631,  0.09454908,  0.13023934,  0.08768496])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['dog'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43260275098796075"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.spatial.distance\n",
    "\n",
    "scipy.spatial.distance.cosine(model['electrolyte'],model['drinks'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do simple queries to retreive words similar to \"socks\" based on cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3561,   737,   789, 79524,   163,   540,   420,   529,  4015,\n",
       "         2966]),\n",
       " array([0.71550285, 0.62992115, 0.62373991, 0.59537892, 0.56506883,\n",
       "        0.54524602, 0.5427218 , 0.53518276, 0.51957802, 0.51318743]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes, metrics = model.cosine('rest')\n",
    "indexes, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5054304978844895"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "scipy.spatial.distance.cosine(model['adult'],model['patient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returned a tuple with 2 items:\n",
    "1. numpy array with the indexes of the similar words in the vocabulary\n",
    "2. numpy array with cosine similarity to each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its possible to get the words of those indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'remainder', u'whole', u'entire', u'wealthiest_men', u'end',\n",
       "       u'outside', u'parts', u'throughout', u'bulk', u'possession'],\n",
       "      dtype='<U78')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a helper function to create a combined response: a numpy [record array](http://docs.scipy.org/doc/numpy/user/basics.rec.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec.array([(u'remainder', 0.71550285), (u'whole', 0.62992115),\n",
       "           (u'entire', 0.62373991), (u'wealthiest_men', 0.59537892),\n",
       "           (u'end', 0.56506883), (u'outside', 0.54524602),\n",
       "           (u'parts', 0.5427218 ), (u'throughout', 0.53518276),\n",
       "           (u'bulk', 0.51957802), (u'possession', 0.51318743)],\n",
       "          dtype=[(u'word', '<U78'), (u'metric', '<f8')])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_response(indexes, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is easy to make that numpy array a pure python response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'remainder', 0.7155028507687243),\n",
       " (u'whole', 0.6299211480784054),\n",
       " (u'entire', 0.6237399134767975),\n",
       " (u'wealthiest_men', 0.5953789201127435),\n",
       " (u'end', 0.565068833388109),\n",
       " (u'outside', 0.5452460225015305),\n",
       " (u'parts', 0.5427218023488299),\n",
       " (u'throughout', 0.5351827648340569),\n",
       " (u'bulk', 0.5195780177930026),\n",
       " (u'possession', 0.5131874266729617)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_response(indexes, metrics).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we trained the model with the output of `word2phrase` we can ask for similarity of \"phrases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'san_francisco', 0.886558000570455),\n",
       " (u'san_diego', 0.8731961018831669),\n",
       " (u'seattle', 0.8455603712285231),\n",
       " (u'las_vegas', 0.8407843553947962),\n",
       " (u'miami', 0.8341796009062884),\n",
       " (u'detroit', 0.8235412519780195),\n",
       " (u'cincinnati', 0.8199138493085706),\n",
       " (u'st_louis', 0.8160655356728751),\n",
       " (u'chicago', 0.8156786240847214),\n",
       " (u'california', 0.8154244925085712)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes, metrics = model.cosine('los_angeles')\n",
    "model.generate_response(indexes, metrics).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its possible to do more complex queries like analogies such as: `king - man + woman = queen` \n",
    "This method returns the same as `cosine` the indexes of the words in the vocab and the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1087, 1145, 7523, 3141, 6768, 1335, 8419, 1826,  648, 1426]),\n",
       " array([ 0.2917969 ,  0.27353295,  0.26877692,  0.26596514,  0.26487509,\n",
       "         0.26428581,  0.26315492,  0.26261258,  0.26136635,  0.26099078]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes, metrics = model.analogy(pos=['king', 'woman'], neg=['man'], n=10)\n",
    "indexes, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'queen', 0.2917968955611075),\n",
       " (u'prince', 0.27353295205311695),\n",
       " (u'empress', 0.2687769174818083),\n",
       " (u'monarch', 0.2659651399832089),\n",
       " (u'regent', 0.26487508713026797),\n",
       " (u'wife', 0.2642858109968327),\n",
       " (u'aragon', 0.2631549214361766),\n",
       " (u'throne', 0.26261257728511833),\n",
       " (u'emperor', 0.2613663460665488),\n",
       " (u'bishop', 0.26099078142148696)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_response(indexes, metrics).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = word2vec.load_clusters('/Users/gautamchheda/Downloads/text8-clusters.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see get the cluster number for individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters['rest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see get all the words grouped on an specific cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.get_words_on_cluster(90).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['take', 'play', 'run', 'live', 'go', 'get', 'turn', 'move',\n",
       "       'running', 'cut', 'moving', 'keep', 'pass', 'look', 'die', 'drive',\n",
       "       'travel', 'begin', 'stop', 'break', 'reach', 'stand', 'carry',\n",
       "       'target', 'setting', 'store', 'enter', 'looking', 'advance',\n",
       "       'draw', 'fit', 'escape', 'moves', 'stay', 'operate', 'getting',\n",
       "       'grow', 'fly', 'walk', 'drop', 'beat', 'starts', 'watch', 'wear',\n",
       "       'switch', 'gets', 'returns', 'driving', 'handle', 'trip', 'check',\n",
       "       'touch', 'clean', 'jump', 'catch', 'blow', 'pick', 'compete',\n",
       "       'finish', 'feed', 'crowd', 'push', 'sending', 'connect', 'trigger',\n",
       "       'warning', 'ride', 'throw', 'burn', 'shoot', 'fill', 'waiting',\n",
       "       'sit', 'wait', 'pointing', 'delay', 'pull', 'arrive', 'bet',\n",
       "       'sends', 'repeat', 'releasing', 'sail', 'exit', 'hide', 'listen',\n",
       "       'emerge', 'fix', 'pushing', 'safely', 'transmit', 'spell',\n",
       "       'listening', 'spare', 'chances', 'insert', 'concentrate', 'sink',\n",
       "       'stopping', 'dial', 'steal', 'climb', 'hang', 'alert', 'sweep',\n",
       "       'disappear', 'picking', 'runners', 'adjust', 'delivering',\n",
       "       'charging', 'calm', 'shed', 'retrieve', 'float', 'shake', 'swim',\n",
       "       'tear', 'accumulate', 'cancel', 'penetrate', 'relax', 'freeze',\n",
       "       'pause', 'dig', 'refrain', 'rotate', 'alarm', 'descend', 'wash',\n",
       "       'swap', 'depart', 'migrate', 'bounce', 'fade', 'explode', 'rip',\n",
       "       'prompt', 'collide', 'navigate', 'sticking', 'breathe', 'fetch',\n",
       "       'wipe', 'steer', 'knocking', 'discard', 'restart', 'learner',\n",
       "       'diverge', 'capitalize', 'detonate', 'propel', 'commute',\n",
       "       'speeding', 'sneak', 'reload', 'revolve', 'commence', 'roam',\n",
       "       'strapped', 'disperse', 'bettor', 'eject', 'erupt', 'chew',\n",
       "       'replenish', 'carve', 'exiting', 'disintegrate', 'fluctuate',\n",
       "       'synergy', 'fend', 'oscillate', 'mutate', 'bidder', 'eavesdrop',\n",
       "       'bumping', 'multichannel', 'thong', 'racking', 'redecoration',\n",
       "       'apologizes', 'nimble'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.get_words_on_cluster(89)[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add the clusters to the word2vec model and generate a response that includes the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.clusters = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes, metrics = model.analogy(pos=['paris', 'germany'], neg=['france'], n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'berlin', 0.32333651414395953, 20),\n",
       " (u'munich', 0.28851564633559, 20),\n",
       " (u'vienna', 0.2768927258877336, 12),\n",
       " (u'leipzig', 0.2690537010929304, 91),\n",
       " (u'moscow', 0.26531859560322785, 74),\n",
       " (u'st_petersburg', 0.259534503067277, 61),\n",
       " (u'prague', 0.25000637367753303, 72),\n",
       " (u'dresden', 0.2495974800117785, 71),\n",
       " (u'bonn', 0.24403155303236473, 8),\n",
       " (u'frankfurt', 0.24199720792200027, 31)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate_response(indexes, metrics).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
